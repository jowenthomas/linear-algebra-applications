{
  "cells": [
    {
      "metadata": {
        "collapsed": true,
        "trusted": false
      },
      "cell_type": "markdown",
      "source": "<h1 align='center'>Adjacency Matrices for Descriptors in <i>Dracula</i></h1>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>Prerequisites</h2>\n<ul>\n    <li>You are familiar with the main characters of the novel.  A quick read of the plot and main characters of the <a href=\"https://en.wikipedia.org/wiki/Dracula\" target=\"_blank\">wiki</a> will suffice.  You could also watch Francis Ford Coppola's <i><a href=\"https://www.imdb.com/title/tt0103874/\" target=\"_blank\">Bram Stoker's Dracula</a></i>; but, be aware that they inject a love narrative between Dracula and Mina that does not exist in the novel, and will seem contraditactory to the characterization of Dracula that we develop below.</li>\n    <li>Familiarity with adjacency matrcies, either from the <a href=\"https://en.wikipedia.org/wiki/Adjacency_matrix\" target=\"_blank\">wiki</a> or by reading the previous article, Matrix Multiplication to Find Connecting Flights.</li>\n</ul>"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>Introduction</h2>\nI think it is fair to say that word choice is a somewhat contentious form of textual analysis.  I sense that students often find it overkill (I'm thinking of the blue curtain meme), teachers find it an accessible gateway into deeper forms of analysis, and professionals find it rather superficial.  But, when reading a text we often come across curiosities that warrant deeper investigation.  That is, it seems desirable to have methods to quantify or substantiate our hunches.  For example, if we presuppose that authors purposefully employ their adjectives, we might question what the consistent use of some particular adjective would indicate about the characters and themes of the text. Reading <i>Dracula</i>, it is hard not to notice the heavy use of red and white.  In this article, we will work to define the circumstances in which Stoker uses these two colors, and then develop some indication that he uses red and white to connote Dracula's association with appetite and death, respectively.  In doing so, we will hopefully find some substantiation of this characterization of Dracula, which is likely to be <i>felt</i> while reading the text.\n\nPlease note that literary analysis is inherently complex due to the layered meanings of most texts.  To extract word choice, while ignoring historical and social context, is at best incomplete.  <i>Dracula</i> itself hints at the need for feminist, religious, and colonialist readings, and the commentary we develop is not intended to supplant other forms of analysis.  Furthermore, I wasn't able to find a source for the type of analysis that we will perform below, and it is based on my own ideas.  As such, its validity should not be taken as anything more than suggestive, and a much more thorough investigation, applied to many texts, is certainly needed to discover the value of such a method.\n\nAlso, I expect that more people are familiar with the character of Dracula through popular culture than through reading the original novel, and it is quite interesting to inspect the disparity between these two sources.  Dracula is understood to be, first and foremost, seductive and cunning when he arises in popular culture.  He is a creature that will convince, mostly, young women to leave their homes or to trick them into allowing him entry so that he may then feed on them.  However, in the text, with some minor exceptions of moments of creativity, some courtly manners, and declarations of his cleverness by Van Helsing, Dracula is portrayed as the embodiment of death and appetite.  He is not a nuanced or tortured intellect, but is a bodily force that consumes and moves on.  There isn't even much indication that he is a sadist, which would at least indicate some level of depth to his actions.  And, it is this inversion of the corporeal and intellectual between the source text and popular conception that I find so intriguing.  Not to digress too far from the topic at hand, but there is an interesting similarity with the creature in Frankenstein, but that the effect is in the opposite direction.  Our popular conception is of a mindless body that wreaks havoc (perhaps unintentionally, you could argue, as a child would), but in Mary Shelley's original text he is a developed and nuanced intellect.  This is just food-for-thought; now back to the task at hand."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>The Use of Red and White</h2>\nTo begin, we would like to establish that Stoker actually uses red and white more commonly than we might initially expect.  To do this, let's look at the 30 most common adjectives used in the novel:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Counter(pos_tags_adj).most_common(30)",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 15,
          "data": {
            "text/plain": "[('good', 202),\n ('more', 189),\n ('other', 186),\n ('old', 185),\n ('own', 185),\n ('such', 182),\n ('great', 173),\n ('poor', 171),\n ('little', 161),\n ('*', 154),\n ('dear', 153),\n ('much', 152),\n ('last', 123),\n ('same', 110),\n ('first', 108),\n ('many', 102),\n ('white', 101),\n ('terrible', 99),\n ('full', 97),\n ('long', 89),\n ('few', 86),\n ('strange', 81),\n ('new', 74),\n ('dead', 70),\n ('whole', 66),\n ('open', 65),\n ('red', 64),\n ('ready', 62),\n ('strong', 58),\n ('sweet', 54)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And, we note that both red and white are in this list, alongside such general adjectives as whole, many, and open.  This seems to indicate that there is something worth investigating.  \n\nBut, it may turn out that Stoker wrote a particularly colorful novel, and he simply loves to establish a rich environment for his characters through lots of description.  So, let's see how the use of red and white compare to other major colors:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "percRW = math.floor((text.count('red')+text.count('white'))/(text.count('red')+text.count('white')+text.count('green')+text.count('blue')+text.count('yellow')+text.count('purple')+text.count('black'))*100)\ncounts = \"Red: \" + str(text.count('red')) + \"\\n\" + \"White: \" + str(text.count('white')) + \"\\n\" + \"Green: \" + str(text.count('green')) + \"\\n\" + \"Blue: \" + str(text.count('blue')) + \"\\n\" + \"Yellow: \" + str(text.count('yellow')) + \"\\n\" + \"Purple: \" + str(text.count('purple')) + \"\\n\" + \"Black: \" + str(text.count('black')) + \"\\n\" + \"\\n\" + \"Red and White as Percentage of Major Color References: \" + str(percRW) + \"%\"\nprint(counts)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Red: 69\nWhite: 101\nGreen: 14\nBlue: 14\nYellow: 6\nPurple: 3\nBlack: 26\n\nRed and White as Percentage of Major Color References: 72%\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And, we see that red and white occur much more than other colors.  Their exceptional use justifies continuing our investigation.\n\nWhile we have shown that red and white happen to be used in large quantites, this doesn't guarantee that their use occurs throughout the book.  It could be that Stoker has a character repeat red 50 times in dialogue over the course of only a couple pages.  For example, Renfield is debatably mad and fixated with blood; perhaps he simply chants \"red, red, red,...\" for an entire page.  To investigate this, let's look at the dispersion of red, white, and the other colors throughout the text:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text.dispersion_plot(['red','white','green','blue','yellow','purple','black'])",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEWCAYAAACNJFuYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4xLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvAOZPmwAAIABJREFUeJzt3XuUHVWZ9/HvD4IESCBiIgKSNCBXEQNp1CCY8IIIykUGFBAH4i0yDqKDUXGhdjMuRlFEGfQVozKAXESjvDJ4AQaNkXDthHATIgGDKAgBRAgy3HzeP2ofUjl17rfupH+ftc7qOrt27f3UPqfP07Wruo4iAjMzs7x1hjsAMzMbeZwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwUY0Sb+QdFybbcySdG2bbdwpaWY7bXRSJ8alhT4HJV3Yyz5t+Dg5WMdIWi5pv062GREHRsT5nWwzT1KfpJC0Mj0elnSFpLeWxfHaiJjfrTia1a1xkXSepOfSWDwu6WpJO7bQTsffC9ZbTg5mmQkRMQ54PXA1cJmkWcMVjKQxw9U38OU0Fq8GHgHOG8ZYbJg4OVhPSDpI0hJJT0i6TtKuqXzb9Bfq7un5FpIeLU3hSJov6YO5dj4k6S5JT0n6XW67kyXdmys/rJU4I+IvEXEWMAicLmmd1P5LfwlLeoOkIUlPpiONM1N56ShktqQHJT0k6RO52NfJxfmYpB9K2rRs2w9I+iPwK0ljJV2Y6j4h6WZJm5WPS2r3s5Lul/SIpAskbVLW7nGS/pjG9pQGx+LvwMXALpXWSzokTbc9keLZKZV/H5gM/Hc6AvlUs6+DDT8nB+u69AF+LvBh4BXAt4HLJa0fEfcCnwYukrQh8F/AeZWmcCS9i+xD+1hgY+AQ4LG0+l5gb2AT4FTgQkmbtxH2T4BXAjtUWHcWcFZEbAxsC/ywbP0+wHbA/sDJuemVE4F3AjOALYC/At8s23YGsBPwNuC4tD9bkY3b8cAzFeKZlR77ANsA44BvlNXZK+3LvsDnSx/ktUgaBxwD3FJh3fbAJcDHgUnAz8mSwcsi4p+BPwIHR8S4iPhyvb5s5HFysF74EPDtiLgxIl5Mc+XPAm8CiIjvAPcANwKbA9X+sv0g2ZTHzZFZFhH3pzZ+FBEPRsQ/IuLS1N4b2oj5wfRz0wrrngdeI2liRKyMiBvK1p8aEU9HxO1kye7oVP5h4JSI+FNEPEuW6I4om0IaTNs+k/p5BfCaNG6LIuLJCvEcA5wZEfdFxErgM8BRZe2eGhHPRMStwK1k02fVzJH0BLCMLNHMqlDnSOBnEXF1RDwPnAFsAOxZo11bgzg5WC9MAT6Rph+eSB88W5H99VzyHbLpi7PTB2clW5EdIRRIOjY3bfVEamtiGzFvmX4+XmHdB4DtgbvTVM9BZesfyC3fz6r9nEJ2LqMU413Ai8BmVbb9PnAl8IM0TfVlSetViGeL1E++zzFl7f4lt/x3sg/9as6IiAkR8aqIOCQd3dXsMyL+kWLfskJdWwM5OVgvPACclj5wSo8NI+ISeGn64uvA94DB0jx8lXa2LS+UNIUsuZwAvCIiJgB3AGoj5sPITsYuLV8REfdExNFk006nA/MkbZSrslVueTKrjkIeAA4sG4exEfHnfPO5fp6PiFMjYmeyv8gPIptSK/cgWeLJ9/kC8HCD+9qK1fqUJLL9Lu2Lb/e8hnNysE5bL51ILT3GkH1wHy/pjcpsJOkdksanbc4CFkXEB4GfAedUafu7ZFMe01I7r0mJYSOyD6MVAJLeR5WTqPVI2kzSCcAA8Jn0F3F5nfdKmpTWPZGKX8xV+ZykDSW9FngfcGkqPwc4LcWMpEmSDq0Ryz6SXidpXeBJsmmmFytUvQT4N0lbp0T7H8ClEfFCM/vepB8C75C0bzqa+QTZVOF1af3DZOc/bA3l5GCd9nOyk6alx2BEDJGdd/gG2UnYZaR57PTheADZyVaAk4DdJR1T3nBE/Ag4jewKmqeA/wdsGhG/A74KXE/2ofQ6YGGTcT8h6WngduDtwLsi4twqdQ8A7pS0kiyxHRUR/5tb/5u0j9eQTdFclcrPAi4HrpL0FHAD8MYaMb0KmEeWGO5K7Vb6J7RzyaagFgB/AP4X+Gjt3W1PRCwF3gucDTwKHEx2Avq5VOWLwGfTFNqcbsZi3SF/2Y9ZZ0jqI/twXq/Lf7WbdZ2PHMzMrMDJwczMCjytZGZmBT5yMDOzguG8uVdbJk6cGH19fcMdhpnZGmXRokWPRsSkevXW2OTQ19fH0NDQcIdhZrZGkXR//VqeVjIzswqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMysYMQlB4mZElcMdxxmZqNZz5KDhKSRkYwGB2s/nzmzcnm7/fT1rWq7Vv1adXqlFMvgYBZ3abmdMcm3WdLMvjbbdydi7YZabVdb18t9L6n02uTfD62aMGFV2+V99PW1Nj759eW/v6X3bf5RUt7/SHjP1Ps9mzmzu+/PEkVE9xoXfcAvgF8D04GvA8cD6wP3Au+LYKXEAWndo8BiYJsIDqrVdn9/fwwNDbUaF/ndrva8vLwT/UD1NjvVbyfkY4HicrttltpoZl+bHZd2xrGbr0Gttqut6+W+12qj3fdAeRut/o4003apLK/a+28kvGcaGYNa6+u3r0UR0V+vXi/+kt8BuAB4K/ABYL8IdgeGgJMkxgLfAQ4G9gZe1YOYzMyshl4kh/sjuAF4E7AzsFBiCXAcMAXYEfhDBPdEEMCF1RqSNFvSkKShFStW9CB0M7PRaUwP+ng6/RRwdQRH51dKTAUaOkCKiLnAXMimlToZpJmZrdLLE8Q3AG+WeA2AxIYS2wN3A1tLbJvqHV2tATMz641eHDkAEMEKiVnAJRLrp+LPRvB7idnAzyQeBa4FdulmLAMDtZ/PmFG5vN1+pkypfaVHqX6p/+FUimVgAM47b/WyTrRZ0sy+Ntt/O/G2u6+ttl1tXS/3vaTSa5N/P7Rqk01g6tTKfUyZArNmVd+23n4NDMD8+avXrbVNef8j4T1Tr50ZM3pzRWNXr1bqpnauVjIzG61G0tVKZma2hnFyMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK+h4cpBYWaX8eIlj0/IsiS063XezJkxYtTw4mH1p98yZ2XLpUVoH9b/Uu1SvmlLbjWjkC8TzMTair6+xeoODMHZssbw8pnzfzcRRrY3S61GtrVrxV4q32f4rlTc7xuXvmXx5pfdWed2ZM1d/X+bLR4LSfuRVel/XGrP8GJS2zf+s10a9912lGPP9dkIjsXWy7U7F3QxFRGcbFCsjGFenznxgTgRDrfbT398fQ0Mtb16Kg9LuS5XrRKyql69fr71q60ttNhNbJ9prtM1a7ZZvXz5+rbyVKrVRra1afXSi/0rlrY5xpbEqV2nsGh374VIpvmpltV6rWuq9p+q972qNYaXyVrTyHm2n7U6+/pIWRUR/vXpNHzlIfErixLT8NYlfpeV9JS5My6dJ3Cpxg8RmqWxQYo7EEUA/cJHEEokNJKZJ/EZikcSVEps3G5eZmXVOK9NKC4C903I/ME5iPWAv4LfARsANEbw+1f1QfuMI5gFDwDERTAVeAM4GjohgGnAucFqljiXNljQkaWjFihUthG5mZo0Y08I2i4BpEuOBZ4HFZElib+BE4Dngilzdt9ZpbwdgF+DqdNi3LvBQpYoRMReYC9m0Uguxm5lZA5pODhE8L7EceB9wHXAbsA+wLXAX8HwEpQ/uFxvoQ8CdEUxvNhYzM+uOVo4cIJsumgO8H7gdOBNYFEHUO9mUPAWMT8tLgUkS0yO4Pk1RbR/BnS3G1rBNNlm1PDAA8+dny+VXOgwMZD9nzKjdXqleNTNmNH7VSb2+Gumv3JQpjdUbGIAvfal+TPn+m42l0nal16NaW7XiX3/99vuvVN7sflXbrvT+qvT65+vOmAFLlhTrNPJ+6IX870lJpfd1rXHLryuNSf5nvTbqve8qxVgvpmY1Elsn2+5k7I1q6WoliX2BXwITInha4vfAORGcmb9aKZ18PiiCWRKDwMoIzpA4HPgP4BlgOtnU0n8Cm5AlrK9H8J1aMXTiaiUzs9Gm0auVOn4pa684OZiZNa9rl7Kamdnaz8nBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwckjFjYHCw9e3b2babfZbqdCq+dtvpRBzDMdZmo03Hv0NaYkwEL3S00Qo6/R3SUvaz1eGQWt+2VY30WarTqfjabacTcQzHWJutLRr9DukxzTfM54BjgAeAR4FFwEHAdcCbgcslLgDOASanzT4ewUKJjYCzgdelvgcj+KnELOAQYENgW+CyCD7VbGxmZtYZTSUHiX7gcGC3tO1isuQAMCGCGanexcDXIrhWYjJwJbATcArwqwjeLzEBuEnif9L2U1O7zwJLJc6O4IHV+9dsYDbA5MmTMTOz7mj2yGEv4KcRPAMg8d+5dZfmlvcDdi5N1QAbS4wH9gcOkZiTysey6ujimgj+ltr9HTAFVk8OETEXmAvZtFKTsZuZWYOaTQ6qse7p3PI6wPRSEnlpYyHg8AiWlpW/keyIoeTFFmIzM7MOafZqpWuBgyXGSowD3lGl3lXACaUnElPT4pXAR1OSQGK3JvvvmnXXhYGB1rdvZ9tu9lmq06n42m2nE3EMx1ibjTZNX60kMQgcDdwPrADmk52gnhPBUKozEfgm2XmGMcCCCI6X2AD4OrAn2VHI8ggOSiek+yOyhCJxBXBGBPOrxdHpq5XMzEaDRq9WaiU5jItgpcSGwAJgdgSLW4yzZU4OZmbN69qlrMBciZ3JTiafPxyJwczMuqvp5BDBe7oRiJmZjRy+fYaZmRU4OZiZWYGTg5mZFTg5mJlZgZODmZkVODmYmVmBk4OZmRU4OZiZWYGTg5mZFTg5mJlZgZODmZkVODmYmVmBk4OZmRU4OZiZWYGTg5mZFTg5mJlZQceSg0SfxB0VyudL1P1KuuE2OFh8PnNm9fq11jXTz3CptL+dbK9X1vZ+R8r7pdtGy36uSZr+DumqDYk+4IoIdikrnw/MiaCjX/jc6e+QliA/FFL2s9rwlNdvtZ/hUml/24lruPZrbe93pLxfum207OdI0Oh3SHd6WmmMxPkSt0nMk9hw9aBYmVs+QuK8tDxJ4scSN6fHmzscl5mZNaHTyWEHYG4EuwJPAh9pcLuzgK9FsAdwOPDdSpUkzZY0JGloxYoVHQnYzMyKxnS4vQciWJiWLwRObHC7/YCdS1M5wMYS4yN4Kl8pIuYCcyGbVmo/XDMzq6TTyaH8A7vW87G55XWA6RE80+F4zMysBZ2eVposMT0tHw1cW7b+YYmdJNYBDsuVXwWcUHoiMbXDcdU1MFB8PmNG9fq11jXTz3CptL+dbK9X1vZ+R8r7pdtGy36uSTp9tdLPgQXAnsA9wD+nsjkRDEkcAZwOPADcAYyLYJbEROCbwE5kRzMLIji+Vn+dvlrJzGw0aPRqpY5NK0WwHNi5wqqZuTrzgHkVtn0UOLJTsZiZWXv8H9JmZlbg5GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFHU8OEivTzz6JOzrd/ppmcDB7lJattzzmI5dfm9WNtPFQRHS2QbEygnESfcAVEezS0Q6S/v7+GBoa6kbTHSVlPyOy5Q4Pt9XhMR+5/NqsrlfjIWlRRPTXq1f3yEHiCxIfyz0/TeJEiU9K3Cxxm8SpddoYK/FfErdL3CKxTyr/ucSuafkWic/n+vxgvdjMzKw7GplW+h5wHIDEOsBRwMPAdsAbgKnANIm31GjjXwEieB1wNHC+xFhgAbC3xMbAC8CbU/29gN+WNyJptqQhSUMrVqxoIHQzM2tF3eQQwXLgMYndgP2BW4A9csuLgR3JkkU1ewHfT+3dDdwPbE+WAN6S1v8MGCexIdAXwdJiLDE3Ivojon/SpEmN7qOZmTVpTIP1vgvMAl4FnAvsC3wxgm83uL2qlN8M9AP3AVcDE4EPAYsabNfMzLqg0eRwGfDvwHrAe8imgL4gcVEEKyW2BJ6P4JEq2y8AjgF+JbE9MBlYGsFzEg8A7wa+AEwCzkiPtcLAQOVl6w2P+cjl12Z1I208Gr5aSeIc4IkITk7PPwYvnTReCbw3gnsrXa2Uzi+cA0wjSywnRfDr1M4XgH0j2FNiC+DPwLQIFteKZ025WsnMbCRp9GqlhpJDOhG9GHhXBPd0IL62OTmYmTWvk5ey7gwsA64ZKYnBzMy6q+45hwh+B2zTg1jMzGyE8L2VzMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqGNTlIrBzO/vMGB4c7gu5a2/evWzxuNlo19B3SLTcuxkTwQo31KyMY10rbnf4OaQm6OBTDbm3fv27xuNnappPfId0ncbfE+RK3ScyT2FBiucTEVKdfYn5aHpSYK3EVcIHELImfSvxSYqnEQJV+Pilxc+rj1OZ218zMOqnRaaUdgLkR7Ao8CXykTv1pwKERvCc9fwNwDDAVeJfEallLYn9gu1RvKjBN4i3ljUqaLWlI0tCKFSsaDN3MzJrVaHJ4IIKFaflCYK869S+P4Jnc86sjeCyV/aTC9vunxy3AYmBHsmSxmoiYGxH9EdE/adKkBkM3M7NmjWmwXvmsawAvsCq5jC1b/3QD2+cJ+GIE324wHjMz66JGjxwmS0xPy0cD1wLLyaaPAA6vs/1bJTaV2AB4J7x0FFJyJfB+KTs5LbGlxCsbjK0jBiqeCVl7rO371y0eNxutGk0OdwHHSdwGbAp8CzgVOEvit8CLdba/Fvg+sAT4cQSrXWYUwVXAxcD1ErcD84DxDe9FB6ztlyyu7fvXLR43G60anVb6RwTHl5X9Fti+vGIEgxW2fySCEyrUHZdbPgs4q8F4zMysi/wf0mZmVlD3yCGC5cAurXYQwXnAea1ub2ZmvecjBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7MCJwczMytwcjAzswInBzMzK3ByMDOzAicHMzMrcHIwM7OClpODRJ/EHRXK50v0t9DeLIlvtBqPmZl1zqg+cpg5s3J56UvlBwdXPUaCenHUWt/MPvRyn7vdT6vt92L/6/XR19f9GJpV7b3RynhVamukvh+G23DErYhobUPRB/wSuBHYDfg9cCzwc2BOBEMS3wL2ADYA5kUwkLbdAzgL2Ah4FtgXOBzoj+AEiXcAnwUOjuDRSv339/fH0NBQS7Hn9oFKu18ql1aVtThMHVUt3kbW19u2vC70Zp+biauX7Xc7rkb66EUMzar23mgl1kptjdT3w3DrZNySFkVE3dmdut8hXccOwAciWChxLvCRsvWnRPC4xLrANRK7AncDlwJHRnCzxMbAM6sC5zDgJODtEfy1zfjMzKwF7SaHByJYmJYvBE4sW/9uidmpn82BnYEAHorgZoAInoSX/orYB+gH9i+V50maDcwGmDx5cpuhm5lZNe2ecyg/0HnpucTWwBxg3wh2BX4GjAVUYbuS+4DxwPYVO4uYGxH9EdE/adKkNkM3M7Nq2k0OkyWmp+WjgWtz6zYGngb+JrEZcGAqvxvYIp13QGK89NIRzP3APwEXSLy2zdjMzKxF7U4r3QUcJ/Ft4B7gW8DBABHcKnELcCfZEcHCVP6cxJHA2RIbkJ1v2K/UYARLJY4BfiRxcAT3thljVTNmVC4fGFj950hRL55a65vZl17ud7f7arX9XoxBvT6mTOl+DM2qFnMr41Vpm5H6fhhuwxF3y1crDbdOXK1kZjbaNHq10qj+PwczM6vMycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMCpwczMyswMnBzMwKnBzMzKzAycHMzAqcHMzMrMDJwczMChQRwx1DSyStAO5vcfOJwKMdDKfTHF97Rnp8MPJjdHztGcnxTYmISfUqrbHJoR2ShiKif7jjqMbxtWekxwcjP0bH156RHl8jPK1kZmYFTg5mZlYwWpPD3OEOoA7H156RHh+M/BgdX3tGenx1jcpzDmZmVttoPXIwM7ManBzMzKxgVCUHSQdIWippmaSTu9zXVpJ+LekuSXdK+lgqH5T0Z0lL0uPtuW0+k2JbKult9eKWtLWkGyXdI+lSSS9rMsblkm5PcQylsk0lXZ3avFrSy1O5JP1niuE2Sbvn2jku1b9H0nG58mmp/WVpWzUR2w65MVoi6UlJHx/u8ZN0rqRHJN2RK+v6mFXro8H4viLp7hTDZZImpPI+Sc/kxvKcVuOota8NxNf111TS+un5srS+r8nX+NJcfMslLRmuMeyZiBgVD2Bd4F5gG+BlwK3Azl3sb3Ng97Q8Hvg9sDMwCMypUH/nFNP6wNYp1nVrxQ38EDgqLZ8D/EuTMS4HJpaVfRk4OS2fDJyelt8O/AIQ8CbgxlS+KXBf+vnytPzytO4mYHra5hfAgW28dn8Bpgz3+AFvAXYH7ujlmFXro8H49gfGpOXTc/H15euVtdNUHNX2tcH4uv6aAh8BzknLRwGXNvMal63/KvD54RrDXj1G05HDG4BlEXFfRDwH/AA4tFudRcRDEbE4LT8F3AVsWWOTQ4EfRMSzEfEHYFmKuWLc6a+Q/wPMS9ufD7yzA6Efmtoqb/NQ4ILI3ABMkLQ58Dbg6oh4PCL+ClwNHJDWbRwR10f2zr+gjfj2Be6NiFr/Ed+T8YuIBcDjFfru9phV66NufBFxVUS8kJ7eALy61j62GEe1fa0bXw2dfE3zcc8D9i39Jd9MjGmbdwOX1Aq8m2PYK6MpOWwJPJB7/idqf1h3TDqE3Q24MRWdkA4bz81ND1SLr1r5K4Ancr/0rexPAFdJWiRpdirbLCIegizBAa9sMb4t03J5eSuOYvVfxpEyfiW9GLNqfTTr/WR/nZZsLekWSb+RtHcu7mbjaPf3q9uv6UvbpPV/S/WbtTfwcETckysbKWPYUaMpOVT6K6Hr1/FKGgf8GPh4RDwJfAvYFpgKPER2iForvmbLm/HmiNgdOBD4V0lvqVF3OOIjzRkfAvwoFY2k8atnRMUk6RTgBeCiVPQQMDkidgNOAi6WtHGLcbQTey9e006N7dGs/ofKSBnDjhtNyeFPwFa5568GHuxmh5LWI0sMF0XETwAi4uGIeDEi/gF8h+wQuVZ81cofJTvsHFNW3rCIeDD9fAS4LMXycOlQNv18pMX4/sTq0xetjveBwOKIeDjFOmLGL6cXY1atj4YoO+l9EHBMmuYgTdc8lpYXkc3jb99iHC3/fvXoNX1pm7R+Exqf3iK33T8Bl+ZiHxFj2A2jKTncDGyXrmZ4GdlUxeXd6izNTX4PuCsizsyV5+cQDwNKV0RcDhyVrqrYGtiO7IRWxbjTL/ivgSPS9scBP20ivo0kjS8tk520vCPFUbp6Jt/m5cCx6YqKNwF/S4fEVwL7S3p5mg7YH7gyrXtK0pvSWBzbTHw5q/2lNlLGr0wvxqxaH3VJOgD4NHBIRPw9Vz5J0rppeRuyMbuvxTiq7Wsj8fXiNc3HfQTwq1KSbMJ+wN0R8dJ00UgZw65o5Kz12vIguxrg92TZ/ZQu97UX2SHhbcCS9Hg78H3g9lR+ObB5bptTUmxLyV3ZUy1usqs1biI7UfcjYP0m4tuG7CqPW4E7S+2SzcNeA9yTfm6aygV8M8VwO9Cfa+v9KYZlwPty5f1kv+j3At8g/Ud+EzFuCDwGbJIrG9bxI0tUDwHPk/2l94FejFm1PhqMbxnZXHbpfVi6aufw9NrfCiwGDm41jlr72kB8XX9NgbHp+bK0fptmXuNUfh5wfFndno9hrx6+fYaZmRWMpmklMzNrkJODmZkVODmYmVmBk4OZmRU4OZiZWYGTg63VJH1N0sdzz6+U9N3c869KOqmN9gclzamybrayu6HeLekmSXvl1u2t7G69SyRtoOzOqXdK+kqT/fdJek+r8ZtV4+Rga7vrgD0BJK0DTARem1u/J7CwkYZK/+zUYN2DgA8De0XEjsDxZLdWeFWqcgxwRkRMjYhnUt3dI+KTjfaR9AFODtZxTg62tltISg5kSeEOsv9cfbmk9YGdgFvSf6V+RdIdyu7BfySApJnKvpfjYrJ/TELSKcq+S+B/gB2q9Ptp4JMR8ShAZHfoPZ/sHlYfJLuz5+clXSTpcmAj4EZJR0p6V4rjVkkLUp/rpvhuVnaDug+nfr4E7J2OQP6tkwNno9uY+lXM1lwR8aCkFyRNJksS15Pd6XI62Z05b4uI5yQdTnbjt9eTHV3cXPpgJrvXzy4R8QdJ08hu17Ab2e/PYmBRha5fW6F8CDguIj6XppiuiIh5AJJWRsTUtHw78LaI+LPSF/OQ/Sfx3yJij5TUFkq6iuz7AOZExEHtjZTZ6pwcbDQoHT3sCZxJlhz2JEsO16U6ewGXRMSLZDdG+w2wB/AkcFNk3ycA2S2bL4t0j6L0V3+jRGN32VwInCfph8BPUtn+wK6SSvcN2oTsPj7PNdG/WcM8rWSjQem8w+vIppVuIDtyyJ9vqPUVpk+XPW/kA/53wLSyst1TeU0RcTzwWbI7dC6R9IpP2M+2AAABDklEQVQU30fTOYqpEbF1RFzVQBxmLXFysNFgIdntqh+P7NbQjwMTyBLE9anOAuDINLc/ieyrIm+q0NYC4LB0hdF44OAqfX4ZOD19sCNpKjAL+L/1gpW0bUTcGBGfJ7sN9VZkd3L9F2W3gUfS9srupvsU2dfQmnWUp5VsNLid7DzCxWVl40onjMm+z2I62d01A/hURPxF0o75hiJisaRLye5uej/w20odRsTlkrYErpMUZB/i743GbsH8FUnbkR0tXJNiuo3syqTF6RbQK8i+XvI24AVJtwLnRcTXGmjfrC7fldXMzAo8rWRmZgVODmZmVuDkYGZmBU4OZmZW4ORgZmYFTg5mZlbg5GBmZgX/H7yngKF4yzUXAAAAAElFTkSuQmCC\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7f479f6be0b8>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Here, each hash indicates that a word occurs, and the horizontal axis here indicates where in the text that occurs, starting at word 0 and progressing to the end of the text.  While we can observe a few gaps and clusters in the occurence of red and white, this certainly indicates that they are used fairly consistently throughout the course of the text.\n\nThese results indicate that there certainly seems to be something worth investigating.  If you performed this analysis on some other random text, it is not very likely that red and white would hold such a notable place both above other colors and amongst very common adjectives.  Let's now turn our attention to how these colors are used.\n\nTo do so, let's first look to see if their use is associated with particular nouns.  Let's start with white.  We can list all of the nouns that are associated:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Counter(white_nouns)",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "Counter({'ashes': 1,\n         'blanket': 1,\n         'candle': 1,\n         'church': 1,\n         'cloud': 1,\n         'clouds': 1,\n         'edges': 3,\n         'face': 9,\n         'faces': 1,\n         'figure': 17,\n         'flesh': 1,\n         'flowers': 3,\n         'foam': 1,\n         'forehead': 2,\n         'frock': 1,\n         'garments': 1,\n         'gloves': 1,\n         'hair': 6,\n         'hairs': 1,\n         'hands': 1,\n         'heat': 1,\n         'light': 1,\n         'lips': 2,\n         'mist': 2,\n         'moustache': 4,\n         'napkin': 1,\n         'nightdress': 1,\n         'nightrobe': 1,\n         'nose': 1,\n         'paper': 1,\n         'road': 1,\n         'sheepskins': 1,\n         'sheet': 1,\n         'shirts': 1,\n         'skin': 11,\n         'sleeves': 2,\n         'teeth': 15,\n         'throat': 1,\n         'tombs': 1,\n         'tree': 1,\n         'trousers': 1,\n         'undergarment': 1,\n         'water': 1,\n         'waves': 1,\n         'wings': 1})"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "But, this is more than a little difficult to read and extract any meaning.  As such, let's limit our results to the six most common:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Counter(white_nouns).most_common(6)",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/plain": "[('figure', 17),\n ('teeth', 15),\n ('skin', 11),\n ('face', 9),\n ('hair', 6),\n ('moustache', 4)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And, let's do the same for red:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Counter(red_nouns).most_common(6)",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 29,
          "data": {
            "text/plain": "[('eyes', 12), ('light', 8), ('lips', 7), ('scar', 6), ('mark', 6), ('sun', 5)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And if we recall that white occurs 101 times and red occurs 69 times in the text, these 6 nouns represent 61% and 63% of their usage, respectively.  \n\nIf we agree that Stoker uses red and white an inordinate amount of times, and we notice that he predominantly uses them with particular nouns, then it is reasonable to ask what effect or meaning he intends by doing so.  Furthermore, we need to question why they both occur so regularly with body parts and lighting.  At this point, while these connections are suggestive of deeper intention of Stoker's usage, they don't really show us what precisely that intention is.  In order to develop some deeper associations, we will need to connect the adjectives with their associated nouns and the character who possesses them.  We tackle this in the next section, and finally introduce some linear algebra to help us do so.\n\nSidenote: Perhaps you are still unconvinced there is anything going on here.  This is certainly fair but has equal responsibility to be supported by argumentation.  If we want to instead argue that this is simply coincidence, we need to be able to reconcile why he finds such frequent need to remind the reader that some teeth are white and some lips are red.  These are default colors for teeth and lips.  And, if it is coincidence, why did he not do so with the color of every other item in the text?  Why are body parts the only items for which he consistently established their color?"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>The Associations of Red and White</h2>\nNow we would like to inspect the connections between red and white, their associated nouns, and the characters who possess these traits.  This creates a number of moving pieces, and we will begin by using an adjacency matrix to help organize all of the connections.\n\nLet's first look at the adjacency matrix for white:"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "$$\n\\begin{array}{r|ccccccc}\n& white & figure & teeth & skin & face & hair & moustache & Dracula & Lucy & Van Helsing & Mina & Jonathan \\\\\n\\hline\nwhite       & 0  & 17 & 15 & 11 & 9  & 6  & 4  & 28 & 21 & 3  & 4  & 1 \\\\\nfigure      & 17 & 0  & 0  & 0  & 0  & 0  & 0  & 5  & 9  & 0  & 0  & 0  \\\\\nteeth       & 15 & 0  & 0  & 0  & 0  & 0  & 0  & 11 & 3  & 0  & 0  & 0  \\\\\nskin        & 11 & 0  & 0  & 0  & 0  & 0  & 0  & 2  & 7  & 0  & 2  & 0  \\\\\nface        & 9  & 0  & 0  & 0  & 0  & 0  & 0  & 3  & 2  & 2  & 2  & 0  \\\\\nhair        & 6  & 0  & 0  & 0  & 0  & 0  & 0  & 3  & 0  & 1  & 0  & 1  \\\\\nmoustache   & 4  & 0  & 0  & 0  & 0  & 0  & 0  & 4  & 0  & 0  & 0  & 0  \\\\\nDracula     & 28 & 5  & 11 & 2  & 3  & 3  & 4  & 0  & 1  & 1  & 1  & 1  \\\\\nLucy        & 21 & 9  & 3  & 7  & 3  & 0  & 0  & 1  & 0  & 1  & 1  & 0  \\\\\nVan Helsing & 3  & 0  & 0  & 0  & 3  & 1  & 0  & 1  & 1  & 0  & 0  & 1  \\\\\nMina        & 4  & 0  & 0  & 2  & 3  & 0  & 0  & 1  & 1  & 0  & 0  & 1  \\\\\nJonathan    & 1  & 0  & 0  & 0  & 0  & 1  & 0  & 1  & 0  & 1  & 1  & 0  \\\\\n\\end{array}\n$$"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "where each entry indicates a count of the instances between the color, a noun, or a characater.  For example, if there is an instance where Dracula is described as having white teeth, then we add 1 to the tallies for white-teeth, Dracula-teeth, and Dracula-white.  \n\nYou will notice that, per usual, an adjacency matrix is a square, symmetric matrix.  In terms of the underlying graph, recall that an adjacency matrix may simply use a binary to indicate if two vertices are connected.  For our adjacency matrix, we are using the interpretation that each value corresponds to the number of edges between adjacent vertices.  So, for the example at hand, we have the advantage of being able to demonstrate how many connections exist within the text.  We could instead normalize all of these values and use a weighted adjacency matrix, but doing so would be equivalent for our desired interpretations.  For the character-to-character values, I have left these as a binary based on how strongly the two characters interact with each other.  We could, theoretically, use the number of shared scenes or references, but this will suffice for our purposes here.\n\nIf we now use this to look at the sum of the elements in a character's vector, then we get a sense of how central the character is to the associations at hand.  We may choose either the row or column vector, as they are equivalent here, and we will keep the white dimension even though it contains information redundant to the noun dimensions.  Specifically, we get:\n\n$$\n\\begin{array}{r|c}\nCharacter & Sum \\\\\n\\hline\nDracula & 62 \\\\\nLucy & 46 \\\\\nMina & 10 \\\\\nVan Helsing & 12 \\\\\nJonathan & 5 \\\\\n\\end{array}\n$$\n\nTo be clear, this indicates the number of edges, i.e., how many walks of length 1, each character (as a vertex) possesses.  We can immediately see that Dracula is at the heart of the matter, but also that Lucy is rather close.  It also is noteworthy that, while graphs are nice to visualize simpler problems, they become very hard to interpret for more complex problems (like having 62 edges for one node) and the linear algebraic representations become easier to inspect.\n\nBefore we come to any sort of interpretation, let's extend these results, so that we may inspect the number of walks of length 2 and 3.  Recall, if our adjacency matrix is denoted $A_w$, then we get this information by finding $A^2_w$ and $A^3_w$.  These are:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(a_2)",
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[2019  329  371  211  168   88  112  362  328   74   90   41]\n [ 329  395  337  260  195  117   88  485  362   65   82   22]\n [ 371  337  355  208  177  123  104  423  326   59   74   26]\n [ 211  260  208  178  132   72   52  317  235   42   53   15]\n [ 140  186  174  123  108   65   48  258  196   32   41   16]\n [  88  117  123   72   66   47   36  170  130   22   28   10]\n [ 112   88  104   52   48   36   32  112   88   16   20    8]\n [ 362  485  423  317  261  170  112  972  688   95  124   33]\n [ 337  362  326  235  198  130   88  691  589   70  105   24]\n [  83   65   59   42   33   22   16   98   70   19   21    5]\n [  99   82   74   53   42   28   20  127  105   21   29    5]\n [  41   22   26   15   18   10    8   33   24    5    5    5]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "with the character vector sums\n$$\n\\begin{array}{r|c}\nCharacter & Sum \\\\\n\\hline\nDracula & 4042 \\\\\nLucy & 3155 \\\\\nMina & 685 \\\\\nVan Helsing & 533 \\\\\nJonathan & 212 \\\\\n\\end{array}\n$$"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(a_3)",
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[33614 39085 35251 25409 20733 13315  9524 64429 48812  7212  9565  2633]\n [39166 11276 11356  7287  5943  3516  3256 17233 14317  2363  3095  1078]\n [35278 11356 11196  7357  5985  3580  3176 18195 14255  2365  3029  1050]\n [25490  7287  7357  4706  3840  2274  2112 11017  9317  1536  2031   695]\n [20295  5434  5526  3510  2841  1662  1592  8006  6544  1171  1492   536]\n [13324  3516  3580  2274  1842  1070  1032  5219  4126   753   938   355]\n [ 9524  3256  3176  2112  1716  1032   896  5336  4064   676   856   296]\n [64372 17206 18186 10990  8895  5216  5336 20529 17168  3471  4297  1723]\n [48914 14485 14423  9422  7398  4189  4112 17426 14220  2841  3518  1333]\n [ 7305  2531  2533  1641  1371   816   724  3726  3003   510   655   243]\n [ 9658  3263  3197  2136  1737  1001   904  4552  3671   646   823   304]\n [ 2651  1078  1050   695   570   355   296  1729  1321   231   292    94]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "with the character vector sums\n\n$$\n\\begin{array}{r|c}\nCharacter & Sum \\\\\n\\hline\nDracula & 177389 \\\\\nLucy & 142281 \\\\\nMina & 31892 \\\\\nVan Helsing & 25058 \\\\\nJonathan & 10362 \\\\\n\\end{array}\n$$"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Let's now repeat this work for the color red, and we will interpret our findings in the next section.\n\nFirst, we have the adjacency matrix for red:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "markdown",
      "source": "$$\n\\begin{array}{r|ccccccc}\n& red & eyes & light & lips & mark & scar & sun & Dracula & Lucy & Van Helsing & Mina & Jonathan \\\\\n\\hline\nred         & 0  & 12 & 8  & 7  & 6  & 6  & 5  & 23 & 6  & 0  & 9  & 0 \\\\\neyes        & 12 & 0  & 0  & 0  & 0  & 0  & 0  & 11 & 0  & 0  & 1  & 0  \\\\\nlight       & 8  & 0  & 0  & 0  & 0  & 0  & 0  & 3  & 2  & 0  & 0  & 0  \\\\\nlips        & 7  & 0  & 0  & 0  & 0  & 0  & 0  & 6  & 1  & 0  & 0  & 0  \\\\\nmark        & 6  & 0  & 0  & 0  & 0  & 0  & 0  & 0  & 3  & 0  & 3  & 0  \\\\\nscar        & 6  & 0  & 0  & 0  & 0  & 0  & 0  & 2  & 0  & 0  & 4  & 0  \\\\\nsun         & 5  & 0  & 0  & 0  & 0  & 0  & 0  & 1  & 0  & 0  & 1  & 0  \\\\\nDracula     & 23 & 11 & 3  & 6  & 0  & 2  & 1  & 0  & 1  & 1  & 1  & 1  \\\\\nLucy        & 6  & 0  & 2  & 1  & 3  & 0  & 0  & 1  & 0  & 1  & 1  & 0  \\\\\nVan Helsing & 0  & 0  & 0  & 0  & 0  & 0  & 0  & 1  & 1  & 0  & 0  & 1  \\\\\nMina        & 9  & 1  & 0  & 0  & 3  & 4  & 1  & 1  & 1  & 0  & 0  & 1  \\\\\nJonathan    & 0  & 0  & 0  & 0  & 0  & 0  & 0  & 1  & 0  & 1  & 1  & 0  \\\\\n\\end{array}\n$$"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now we would like to inspect the character vector sums for the adjacency matrices representing the walks of length 1, 2, and 3, given by, say, $A_r$, $A^2_r$, and $A^3_r$, respecitively.  All together, these are:\n\n$$\n\\begin{array}{ccc}\n\\begin{array}{r|c}\nCharacter & Sum \\\\\n\\hline\nDracula & 50 \\\\\nMina & 21 \\\\\nLucy & 15 \\\\\nJonathan & 3 \\\\\nVan Helsing & 3 \\\\\n\\end{array} & \\begin{array}{r|c}\nCharacter & Sum \\\\\n\\hline\nDracula & 2346 \\\\\nMina & 921 \\\\\nLucy & 642 \\\\\nJonathan & 74 \\\\\nVan Helsing & 68 \\\\\n\\end{array} & \\begin{array}{r|c}\nCharacter & Sum \\\\\n\\hline\nDracula & 76739 \\\\\nMina & 28484 \\\\\nLucy & 20284 \\\\\nJonathan & 3335 \\\\\nVan Helsing & 3062 \\\\\n\\end{array} \\\\\n\\end{array}\n$$"
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "And, again we see that Dracula holds the first position (although, he holds a very substantial margin here that he did not hold for white) and Lucy has a significant number.  But, it is noteworthy that Mina now also has a substantial portion.\n\nNow that we have collected our results, let's turn to providing some interpretation."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>Interpretation</h2>\nIf we look at our linear algebraic results for white, we find that Dracula and Mina are almost equally central and have approximately 5 times as many connections as the other characters.  To be clear, we should not expect any character to have zero connections, both because they are connected to the other charactes and Stoker's use of a general color does not need to be unifaceted.  The proportions of how white is used are the real clues.  But, what attribute do Dracula and Lucy possess (or lack) that the other characters do not? To answer this, let's look at the specific nouns associated to white, namely figure, teeth, skin, face, hair, and moustache. All of these are associated with the body, but more precisely, all of these are the whitened versions that we would expect to see in a corpse.  Particularly in the use of figure, skin, and face, Stoker deliberately reminds the reader that Dracula and Mina are the \"dead Un-Dead\". Thus, we should not picture them as having the usual pigmentation that we would expect, but rather as walking corpses.  Stoker's use of hair and moustache are much the same, although this is slightly complicated by Van Helsing being old and having white hair.  The interpretation for teeth is two-fold: (i) exposed teeth also signify a corpse; (ii) they are Dracula's means for bringing about death.  While I do not want to wander too deep into corroborating textual evidence, I think it is noteworthy that Stoker directly references the legend of the <a href=\"https://en.wikipedia.org/wiki/White_Lady_(ghost)\" target=\"_blank\">white lady</a> in chapter six. Ultimately, Stoker's use of the color white is very strongly associated with death, and it serves as a useful reminder of the strange nature of Dracula and his victim in a time where the images of vampires, zombies, and the living undead were not widespread in the culture, as they are today.\n\nIf we look at our linear algebraic results for red, we find that Dracula is incredibly central relative to the other characters and that Mina and Lucy have 7-9 times more connections than Jonathan and Van Helsing.  These proportions are rather curious: what is it that Dracula has a lot of, Mina and Lucy have a good deal of, and Jonathan and Van Helsing have very little of? Again, to answer this we need to look at the specific nouns associated to red, namely eyes, light, lips, mark, scar, and sun.  From reading the text, red light and the red sun are used to paint a particular scene, well, red.  Light is also used in the sense of the light in his eyes, creating a bridge to the other four nouns.  Eyes, lips, mark, and scar all connect to organs that can be flushed with blood.  That is to say, all of the nouns express a notion that a character or an environment are bathed in blood, the very thing that nourishes the vampire characters.  As such, Stoker uses red to signify appetite, and you could argue a deranged or animalistic version of appetite at that (note: you could certainly read \"sensuality\" or \"carnality\" here and I wouldn't argue much, but I think the baser version \"appetite\" is more accurate).  Dracula and Lucy's connection with appetite are clear as Stoker demonstrates them feeding, but Mina is slightly more nuanced.  Mina begins the transformation to vampire and hence is strongly connected to red, but she never completes this transformation by dying.  This is consistent with our results above that Mina is not strongly associated with white and death.\n\nJonathan is an interesting case that I want to briefly mention.  He is clearly victimized by Dracula, and thus confronts appetite and death.  But, he never actually comes to possess any of these attributes.  This seems consistent with our work above in that Jonathon has no substantial connection with red nor white."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>Closing Thoughts</h2>\nUltimately, besides attempting to find a somewhat novel use of matrices and matrix multiplication, my objectives for this article were to encourage the inclination to quantify your hunches and to work with, not against, the results of such quantifications.  In practice, we may find that some problems (like literary analysis) are not particularly amenable to mathematical arguments, but we should remain open to the possibility that some portion of the question will bend to them. The above results are in no way definitive proof of Stoker's or the text's intended meaning; we would, at least, need to situate our analysis amongst other methods.  However, I think we have clearly established that red and white are used in a substantial way, and their connections with certain characters are too consistent to simply be accidental.  That is, your version of the Interpretations section may differ from mine, but to call the use of red and white incidental is to actively work against the work in the first two sections.\n\nIn the beginning, I claimed that Dracula's character almost exclusively consists of death and appetite.  I have not shown this exclusitivity yet, and perhaps while he possesses these traits he may have many other good traits that create a nuanced character.  Within the text, this is not the case though.  To substantiate this, we could apply similar methods to the other common adjectives to see Dracula's connection to those with a positive or negative connotation.  Instead, I think it would be a better use of your time to read the original novel, create your own arguments, and draw your own conclusions.  Happy reading."
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "<h2>Appedix: Tools Used</h2>\nTo do our textual analysis, we will use the Natural Language Toolkit, <a href=\"https://www.nltk.org/\" target=\"_blank\">NLTK</a>.  It has a very interesting book that will walk you through some common techniques of natural language process, if you are interested.\n\nFirst, we need to install the package and setup our other libraries:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "!pip install -U nltk",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Requirement already up-to-date: nltk in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (3.3)\nRequirement already satisfied, skipping upgrade: six in /home/nbuser/anaconda3_420/lib/python3.5/site-packages (from nltk) (1.11.0)\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import nltk\nnltk.download('punkt') ",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package punkt to /home/nbuser/nltk_data...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import numpy as np\nimport matplotlib\nfrom collections import Counter",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now, we need to access the plain-text file and feed it into NLTK:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "f = open('dracula.txt')\nraw = f.read()",
      "execution_count": 14,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "tokens = nltk.word_tokenize(raw)",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text = nltk.Text(tokens)",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "Now that we can access the text, we can use some handy functions to do so basic language analysis:"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "import math\npercRW = math.floor((text.count('red')+text.count('white'))/(text.count('red')+text.count('white')+text.count('green')+text.count('blue')+text.count('yellow')+text.count('purple')+text.count('black'))*100)\ncounts = \"Red: \" + str(text.count('red')) + \"\\n\" + \"White: \" + str(text.count('white')) + \"\\n\" + \"Green: \" + str(text.count('green')) + \"\\n\" + \"Blue: \" + str(text.count('blue')) + \"\\n\" + \"Yellow: \" + str(text.count('yellow')) + \"\\n\" + \"Purple: \" + str(text.count('purple')) + \"\\n\" + \"Black: \" + str(text.count('black')) + \"\\n\" + \"\\n\" + \"Red and White as Percentage of Major Color References: \" + str(percRW) + \"%\"\nprint(counts)",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Red: 69\nWhite: 101\nGreen: 14\nBlue: 14\nYellow: 6\nPurple: 3\nBlack: 26\n\nRed and White as Percentage of Major Color References: 72%\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "text.dispersion_plot(['red','white','green','blue','yellow','purple','black'])",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": "<matplotlib.figure.Figure at 0x7f4cd23357f0>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "note: we could use blood as a strong signifier of red, and it would match our results.  I would prefer to keep it more direct for this article.\n\nNext, I will find the associated nouns manually, and do some slight normalization of terminology to ease our analysis. I really should perform the following with dependency trees and automote this generation. "
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "white_nouns = ['sleeves', 'trousers', 'shirts', 'undergarment', 'sleeves', 'water', 'tree', 'sheepskins', 'cloud', 'road', 'teeth', 'blanket', 'teeth', 'moustache', 'teeth', 'hands', 'moustache', 'teeth', 'teeth', 'teeth', 'heat', 'hair', 'moustache', 'skin', 'figure', 'figure', 'frock', 'waves', 'clouds', 'foam', 'wings', 'figure', 'figure', 'figure', 'figure', 'figure', 'face', 'edges', 'edges', 'figure', 'paper', 'edges', 'face', 'skin', 'lips', 'lips', 'flowers', 'hairs', 'gloves', 'teeth', 'faces', 'sheet', 'face', 'face', 'throat', 'face', 'flowers', 'teeth', 'face', 'garments', 'skin', 'skin', 'flowers', 'candle', 'figure', 'figure', 'figure', 'teeth', 'figure', 'face', 'skin', 'figure', 'napkin', 'tombs', 'figure', 'figure', 'figure', 'flesh', 'teeth', 'mist', 'face', 'church', 'moustache', 'hair', 'teeth', 'face', 'figure', 'nightdress', 'nose', 'teeth', 'nightrobe', 'ashes', 'mist', 'light', 'teeth', 'hair', 'skin', 'forehead', 'hair', 'skin', 'skin', 'hair', 'forehead', 'teeth', 'hair', 'skin', 'skin', 'skin', 'teeth']\nCounter(white_nouns).most_common(6)",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 22,
          "data": {
            "text/plain": "[('figure', 17),\n ('teeth', 15),\n ('skin', 11),\n ('face', 9),\n ('hair', 6),\n ('moustache', 4)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "red_nouns= ['pepper', 'lips', 'tongue', 'lips', 'eyes', 'lips', 'tongue', 'cheeks', 'light', 'lips', 'jaws', 'eyes', 'points', 'light', 'eyes', 'eyes', 'sun', 'mark', 'mark', 'eyes', 'light', 'light', 'lips', 'mark', 'scar', 'eyes', 'lips', 'light', 'eyes', 'eyes', 'mouth', 'sun', 'eyes', 'sun', 'eyes', 'mark', 'lips', 'eyes', 'scar', 'scar', 'skin', 'sun', 'light', 'frock', 'scar', 'face', 'skin', 'mark', 'mark', 'scar', 'sun', 'scar', 'light', 'eyes', 'sky', 'light']\nCounter(red_nouns).most_common(6)",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 28,
          "data": {
            "text/plain": "[('eyes', 12), ('light', 8), ('lips', 7), ('scar', 6), ('mark', 6), ('sun', 5)]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "slideshow": {
          "slide_type": "subslide"
        }
      },
      "cell_type": "markdown",
      "source": "Next, we establish our adjacency matrices, take their powers, and sum the vector elements.  We do this first for white (a), then for red (b):"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "a=[[0,17,15,11,9,6,4,28,21,3,4,1],\n   [17,0,0,0,0,0,0,5,9,0,0,0],\n   [15,0,0,0,0,0,0,11,3,0,0,0],\n   [11,0,0,0,0,0,0,2,7,0,2,0],\n   [9,0,0,0,0,0,0,3,2,2,2,0],\n   [6,0,0,0,0,0,0,3,0,1,0,1],\n   [4,0,0,0,0,0,0,4,0,0,0,0],\n   [28,5,11,2,3,3,4,0,1,1,1,1],\n   [21,9,3,7,3,0,0,1,0,1,1,0],\n   [3,0,0,0,3,1,0,1,1,0,0,1],\n   [4,0,0,2,3,0,0,1,1,0,0,1],\n   [1,0,0,0,0,1,0,1,0,1,1,0]\n   ]\na_2 = np.matmul(a, a)\nprint(a_2)",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[2019  329  371  211  168   88  112  362  328   74   90   41]\n [ 329  395  337  260  195  117   88  485  362   65   82   22]\n [ 371  337  355  208  177  123  104  423  326   59   74   26]\n [ 211  260  208  178  132   72   52  317  235   42   53   15]\n [ 140  186  174  123  108   65   48  258  196   32   41   16]\n [  88  117  123   72   66   47   36  170  130   22   28   10]\n [ 112   88  104   52   48   36   32  112   88   16   20    8]\n [ 362  485  423  317  261  170  112  972  688   95  124   33]\n [ 337  362  326  235  198  130   88  691  589   70  105   24]\n [  83   65   59   42   33   22   16   98   70   19   21    5]\n [  99   82   74   53   42   28   20  127  105   21   29    5]\n [  41   22   26   15   18   10    8   33   24    5    5    5]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "a_3 = np.matmul(a_2, a)\nprint(a_3)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[33614 39085 35251 25409 20733 13315  9524 64429 48812  7212  9565  2633]\n [39166 11276 11356  7287  5943  3516  3256 17233 14317  2363  3095  1078]\n [35278 11356 11196  7357  5985  3580  3176 18195 14255  2365  3029  1050]\n [25490  7287  7357  4706  3840  2274  2112 11017  9317  1536  2031   695]\n [20295  5434  5526  3510  2841  1662  1592  8006  6544  1171  1492   536]\n [13324  3516  3580  2274  1842  1070  1032  5219  4126   753   938   355]\n [ 9524  3256  3176  2112  1716  1032   896  5336  4064   676   856   296]\n [64372 17206 18186 10990  8895  5216  5336 20529 17168  3471  4297  1723]\n [48914 14485 14423  9422  7398  4189  4112 17426 14220  2841  3518  1333]\n [ 7305  2531  2533  1641  1371   816   724  3726  3003   510   655   243]\n [ 9658  3263  3197  2136  1737  1001   904  4552  3671   646   823   304]\n [ 2651  1078  1050   695   570   355   296  1729  1321   231   292    94]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ma = np.matrix(a)\nprint(ma.sum(axis=1))",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[119]\n [ 31]\n [ 29]\n [ 22]\n [ 18]\n [ 11]\n [  8]\n [ 60]\n [ 46]\n [ 10]\n [ 12]\n [  5]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(a_2.sum(axis=1))",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[4193 2737 2583 1775 1387  909  716 4042 3155  533  685  212]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(a_3.sum(axis=1))",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[309582 119886 116822  77662  58609  38029  32940 177389 142281  25058\n  31892  10362]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "b = [[0,12,8,7,6,6,5,23,6,0,9,0],\n     [12,0,0,0,0,0,0,11,0,0,1,0],\n     [8,0,0,0,0,0,0,3,2,0,0,0],\n     [7,0,0,0,0,0,0,6,1,0,0,0],\n     [6,0,0,0,0,0,0,0,3,0,3,0],\n     [6,0,0,0,0,0,0,2,0,0,4,0],\n     [5,0,0,0,0,0,0,1,0,0,1,0],\n     [23,11,3,6,0,2,1,0,1,1,1,1],\n     [6,0,2,1,3,0,0,1,0,1,1,0],\n     [0,0,0,0,0,0,0,1,1,0,0,1],\n     [9,1,0,0,3,4,1,1,1,0,0,1],\n     [0,0,0,0,0,0,0,1,0,1,1,0]]\nb_2 = np.matmul(b, b)\nprint(b_2)",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[1000  262   81  144   45   82   32  230   73   29   88   32]\n [ 262  266  129  150   75   98   72  277   84   11  119   12]\n [  81  129   77   76   54   54   43  186   51    5   77    3]\n [ 144  150   76   86   45   54   41  162   48    7   70    6]\n [  45   75   54   45   54   48   33  144   39    3   57    3]\n [  82   98   54   54   48   56   36  142   42    2   56    6]\n [  32   72   43   41   33   36   27  116   32    1   46    2]\n [ 230  277  186  162  144  142  116  704  152    2  229    2]\n [  73   84   51   48   39   42   32  152   53    1   64    3]\n [  29   11    5    7    3    2    1    2    1    3    3    1]\n [  88  119   77   70   57   56   46  229   64    3  111    1]\n [  32   12    3    6    3    6    2    2    3    1    1    3]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "b_3 = np.matmul(b_2, b)\nprint(b_3)",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[12242 14618  8836  8453  6483  6812  5318 27407  6788   335 10092   347]\n [14618  6310  3095  3580  2181  2602  1706 10733  2612   373  3686   407]\n [ 8836  3095  1308  1734   870  1166   668  4256  1146   240  1519   268]\n [ 8453  3580  1734  2028  1218  1468   952  5986  1476   216  2054   239]\n [ 6483  2181   870  1218   558   786   426  2523   789   186  1053   204]\n [ 6812  2602  1166  1468   786  1000   608  3704   998   190  1430   200]\n [ 5318  1706   668   952   426   608   322  2083   581   150   780   163]\n [27407 10733  4256  5986  2523  3704  2083 10652  3281   858  4321   935]\n [ 6788  2612  1146  1476   789   998   581  3281   922   208  1266   217]\n [  335   373   240   216   186   190   150   858   208     4   294     8]\n [10092  3686  1519  2054  1053  1430   780  4321  1266   294  1646   343]\n [  347   407   268   239   204   200   163   935   217     8   343     4]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "mb = np.matrix(b)\nprint(mb.sum(axis=1))",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[[82]\n [24]\n [13]\n [14]\n [12]\n [12]\n [ 7]\n [50]\n [15]\n [ 3]\n [21]\n [ 3]]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(b_2.sum(axis=1))",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[2098 1555  836  889  600  676  481 2346  642   68  921   74]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(b_3.sum(axis=1))",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[107731  51903  25106  29404  17277  20964  13757  76739  20284   3062\n  28484   3335]\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "To substantiate that red and white occur abnormally often, we need to establish their place in the most common adjectives.  To do this, we will first impose parts-of-speech tags on the text, and create a subset that is tagged as one of the forms of an adjective (JJ,JJR,JJS)."
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nltk.download('averaged_perceptron_tagger')",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": "[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /home/nbuser/nltk_data...\n[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "execution_count": 20,
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pos_tags = nltk.pos_tag(text)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "pos_tags_adj = [x[0] for x in pos_tags if x[1] == \"JJ\" or x[1] == \"JJR\" or x[1] == \"JJS\" ]",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "Counter(pos_tags_adj).most_common(50)",
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 23,
          "data": {
            "text/plain": "[('good', 202),\n ('more', 189),\n ('other', 186),\n ('own', 185),\n ('old', 185),\n ('such', 182),\n ('great', 173),\n ('poor', 171),\n ('little', 161),\n ('*', 154),\n ('dear', 153),\n ('much', 152),\n ('last', 123),\n ('same', 110),\n ('first', 108),\n ('many', 102),\n ('white', 101),\n ('terrible', 99),\n ('full', 97),\n ('long', 89),\n ('few', 86),\n ('strange', 81),\n ('new', 74),\n ('dead', 70),\n ('whole', 66),\n ('open', 65),\n ('red', 64),\n ('ready', 62),\n ('strong', 58),\n ('sweet', 54),\n ('young', 53),\n ('true', 52),\n ('heavy', 50),\n ('present', 48),\n ('able', 47),\n ('happy', 45),\n ('to-night', 45),\n ('big', 44),\n ('small', 42),\n ('free', 41),\n ('quick', 41),\n ('late', 41),\n ('certain', 40),\n ('sure', 39),\n ('wild', 38),\n ('least', 38),\n ('better', 38),\n ('hard', 37),\n ('high', 37),\n ('dark', 37)]"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}